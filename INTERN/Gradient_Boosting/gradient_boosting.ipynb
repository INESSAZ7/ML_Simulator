{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cafc73a6",
   "metadata": {},
   "source": [
    "* https://www.youtube.com/watch?v=wnTlsXaVj-s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa92e7a",
   "metadata": {},
   "source": [
    "### Step-1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af258078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b7639d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>dependents</th>\n",
       "      <th>has_property</th>\n",
       "      <th>has_car</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>job_tenure</th>\n",
       "      <th>has_education</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_period</th>\n",
       "      <th>delay_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>32181</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>142434</td>\n",
       "      <td>1770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>52789</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>120887</td>\n",
       "      <td>1590</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>70535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>325</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>188766</td>\n",
       "      <td>810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>85271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>525</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>406792</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>19974</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>618</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>155240</td>\n",
       "      <td>1560</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  dependents  has_property  has_car  credit_score  job_tenure  \\\n",
       "0   76   32181           3             0        1           814          28   \n",
       "1   69   52789           8             1        0           501          28   \n",
       "2   19   70535           1             0        1           325          26   \n",
       "3   31   85271           1             0        1           525          29   \n",
       "4   18   19974           2             0        1           618          34   \n",
       "\n",
       "   has_education  loan_amount  loan_period  delay_days  \n",
       "0              1       142434         1770           0  \n",
       "1              1       120887         1590           7  \n",
       "2              1       188766          810           0  \n",
       "3              1       406792          330           0  \n",
       "4              1       155240         1560          43  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8701b056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1, 814,  28,   1],\n",
       "       [  0, 501,  28,   1],\n",
       "       [  1, 325,  26,   1],\n",
       "       ...,\n",
       "       [  1, 836,  28,   0],\n",
       "       [  0, 370,  39,   0],\n",
       "       [  0, 852,  18,   0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['has_car','credit_score', 'job_tenure', 'has_education' ]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "aabc9873",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['delay_days'].to_numpy()\n",
    "X = df[['has_car','credit_score', 'job_tenure', 'has_education' ]].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ff387",
   "metadata": {},
   "source": [
    "### Step-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06e4a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class GradientBoostingRegressor():\n",
    "    \"\"\"Gradient boosting regressor.\"\"\"\n",
    "    def __init__(self):    \n",
    "        self.base_pred_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model to the data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "            y: array-like of shape (n_samples,)\n",
    "\n",
    "        Returns:\n",
    "            GradientBoostingRegressor: The fitted model.\n",
    "            \n",
    "        \"\"\"\n",
    "        self.base_pred_ = np.mean(y)\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the target of new data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "            y: array-like of shape (n_samples,)\n",
    "            The predict values.\n",
    "            \n",
    "        \"\"\"\n",
    "        predictions = np.full(X.shape[0], fill_value=self.base_pred_)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aef12c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0c29d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc4374",
   "metadata": {},
   "source": [
    "### Step-3: loss-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bfe36bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def mse(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"Mean squared error loss function and gradient.\"\"\"\n",
    "    loss = float(np.sum(np.square(y_pred - y_true)) * 1/y_true.shape)\n",
    "    grad = y_pred - y_true\n",
    "    return loss, grad\n",
    "\n",
    "\n",
    "def mae(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"Mean absolute error loss function and gradient.\"\"\"\n",
    "    loss = float(np.sum(np.abs(y_pred - y_true)) * 1/y_true.shape)\n",
    "    grad = np.sign(y_pred - y_true)\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7cf51a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.626923999999999,\n",
       " array([ 1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "         1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
       "        -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "         1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "         1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "         1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "        -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "        -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "        -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "        -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "        -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "         1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
       "        -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,\n",
       "         1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "         1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "         1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "        -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
       "         1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "        -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "        -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "        -1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,\n",
       "         1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "         1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "         1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y, y_pred)\n",
    "mae(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1cd42",
   "metadata": {},
   "source": [
    "### Step-4: Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "17a2e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        min_samples_split=2,\n",
    "        loss=\"mse\",\n",
    "        verbose=False,\n",
    "        subsample_size=0.5, \n",
    "        replace=False\n",
    "    ):\n",
    "        \n",
    "        self.base_pred_ = None\n",
    "        self.trees_ = []\n",
    "        if loss == \"mse\":\n",
    "            self.loss = self._mse\n",
    "        else: \n",
    "            self.loss = loss\n",
    "            \n",
    "        self.n_estimators=n_estimators\n",
    "        self.learning_rate=learning_rate\n",
    "        self.max_depth=max_depth\n",
    "        self.min_samples_split=min_samples_split\n",
    "        self.verbose=verbose\n",
    "        self.subsample_size=subsample_size\n",
    "        self.replace=replace\n",
    "        self.loss_list_= []\n",
    "        \n",
    "    def _mse(self, y_true, y_pred):\n",
    "        loss = np.mean(np.square(y_pred - y_true))\n",
    "        grad = y_pred - y_true\n",
    "        return loss, grad\n",
    "    \n",
    "    def _subsample(self, X, grad): \n",
    "        index = np.random.choice(X.shape[0], size=int(X.shape[0]*self.subsample_size), replace=self.replace)\n",
    "        sub_X = X[index]\n",
    "        sub_grad = grad[index]\n",
    "        return sub_X, sub_grad\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the model to the data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "            y: array-like of shape (n_samples,)\n",
    "\n",
    "        Returns:\n",
    "            GradientBoostingRegressor: The fitted model.\n",
    "        \"\"\"\n",
    "        self.base_pred_ = np.mean(y)\n",
    "        y_pred = np.full(int(X.shape[0]), fill_value=self.base_pred_)\n",
    "        for i in range(self.n_estimators):\n",
    "            loss_, grad_ = self.loss(y, y_pred)\n",
    "            X_sub, grad_sub = self._subsample(X, grad_)\n",
    "            b_i = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            b_i.fit(X_sub, (-grad_sub))\n",
    "            y_pred += self.learning_rate*b_i.predict(X)\n",
    "            self.trees_.append(b_i)\n",
    "            self.loss_list_.append(loss_)\n",
    "            if self.verbose:\n",
    "                print(loss_) \n",
    "            \n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the target of new data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "            y: array-like of shape (n_samples,)\n",
    "            The predict values.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = np.full(X.shape[0], fill_value=self.base_pred_)\n",
    "        for tree_i in self.trees_:\n",
    "            predictions += self.learning_rate*tree_i.predict(X)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75a3ae",
   "metadata": {},
   "source": [
    "##### Проверка класса, график"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6c02c80a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Default loss\n",
      "408.523319\n",
      "407.2065767522467\n",
      "405.20021289155613\n",
      "404.04532331531993\n",
      "399.78833655235945\n",
      "399.0043959979868\n",
      "395.8809302218465\n",
      "394.5874381781824\n",
      "392.0885113910718\n",
      "390.90293715309446\n",
      "\n",
      "Model with Specific loss\n",
      "408.523319\n",
      "406.63663717318286\n",
      "403.96881422575524\n",
      "401.80934042490117\n",
      "398.36004367259903\n",
      "397.4080935668928\n",
      "396.4988073393905\n",
      "394.2420479192034\n",
      "392.04725375627214\n",
      "389.74877354446846\n",
      "\n",
      "Model with User-defined loss\n",
      "14.626923999999999\n",
      "14.609006241472256\n",
      "14.594308360116324\n",
      "14.577811805758731\n",
      "14.562574450386828\n",
      "14.547081593243973\n",
      "14.533481026741512\n",
      "14.517458736101116\n",
      "14.504158183773317\n",
      "14.488168267013993\n"
     ]
    }
   ],
   "source": [
    "# Поддержка трех вариантов передачи функции потерь\n",
    "\n",
    "\n",
    "# Example 1. Default loss\n",
    "print('Model with Default loss')\n",
    "model = GradientBoostingRegressor(n_estimators=10, verbose=True)\n",
    "model.fit(X, y)\n",
    "\n",
    "print('\\nModel with Specific loss')\n",
    "# Example 2. Specific loss from list of supported functions\n",
    "model = GradientBoostingRegressor(n_estimators=10, verbose=True, loss=\"mse\")\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "# Example 3. User-defined function\n",
    "def user_loss(y_true, y_pred):\n",
    "    loss = float(np.sum(np.abs(y_pred - y_true)) * 1/y_true.shape)\n",
    "    grad = np.sign(y_pred - y_true)\n",
    "    return loss, grad\n",
    "print('\\nModel with User-defined loss')\n",
    "model = GradientBoostingRegressor(n_estimators=10, verbose=True, loss=user_loss)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e83a39d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE | Train = 280.8948934972339 | Test = 415.8267934680004\n",
      "RMSE | Train = 16.75991925688289 | Test = 20.391831537848688\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Разбиение на train и test\n",
    "# Отрисовка метрики ошибки\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = np.array(X[:800])\n",
    "y_train = np.array(y[:800])\n",
    "\n",
    "\n",
    "X_test = np.array(X[800:])\n",
    "y_test = np.array(y[800:])\n",
    "\n",
    "\n",
    "\n",
    "# def mae(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "#     \"\"\"Mean absolute error loss function and gradient.\"\"\"\n",
    "#     loss = float(np.sum(np.abs(y_pred - y_true)) * 1/y_true.shape)\n",
    "#     grad = np.sign(y_pred - y_true)\n",
    "#     return loss, grad\n",
    "\n",
    "# model = GradientBoostingRegressor(loss=mae)\n",
    "\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "mse    = np.mean( ( pred - y_test ) ** 2 )\n",
    "print(f\"MSE | Train = {model.loss_list_[-1]} | Test = {mse}\")\n",
    "print(f\"RMSE | Train = {np.sqrt(model.loss_list_[-1])} | Test = {np.sqrt(mse)}\")\n",
    "plt.title('MSE')\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel(\"Trees/Iterations\")\n",
    "plt.plot(model.loss_list_)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2e261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
